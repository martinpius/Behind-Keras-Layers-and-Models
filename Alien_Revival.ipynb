{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alien-Revival.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrMwnPI7o7vuqfyEmzkIxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/Behind-Keras-Layers-and-Models/blob/main/Alien_Revival.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb6OSq06ekLx",
        "outputId": "3177ee8e-308f-43a6-f8d7-14bee819c61f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import tensorflow as tf\n",
        "  print(f\"You are using Google colab with tensorflow version: {tf.__version__}\")\n",
        "except Exception as e:\n",
        "  COLAB = False\n",
        "  print(f\"{type(e)}: {e}\\n...Please Load Your Drive...\")\n",
        "\n",
        "def time_fmt(t):\n",
        "  h = int(t / (60 * 60))\n",
        "  m = int(t % (60 * 60)/60)\n",
        "  s = int(t % 60)\n",
        "  return f\"{h}: {m:>02}: {s:>05.2f}\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "You are using Google colab with tensorflow version: 2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AcxDmllif-dv",
        "outputId": "85d81924-fcdc-4780-f0d6-a34e9271b201"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "time_fmt(123.4903)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0: 02: 03.00'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndGCumHOhdC4"
      },
      "source": [
        "#End to end autoencoder's for cifar10 dataset\n",
        "#We will train the autoencoder in two different way\n",
        "#As a ussual MLP and as a CNN"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdcvJQaRh4CS"
      },
      "source": [
        "#The ussual MLP "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIGKuhmfh7Wr"
      },
      "source": [
        "#Defining the sampling class (layer subclassing): We sample from the normal distribution to instantiate the decoder's inputs"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWTmjALyiMfO"
      },
      "source": [
        "class SampleGenerator(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    mu, sigma = inputs\n",
        "    dim1 = tf.shape(mu)[0]\n",
        "    dim2 = tf.shape(mu)[1]\n",
        "    eps = tf.keras.backend.random_normal(shape = (dim1, dim2))\n",
        "    return mu + tf.exp(0.5 * sigma) * eps\n",
        "  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "360kfDm6i6sG"
      },
      "source": [
        "#Defining  the encoder's class (layer-subclassing) which encode the original data/image to some representation"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH_B4j0RjIPm"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, hidden = 64, intermediate = 128, name = 'encoder', **kwargs):\n",
        "    super(Encoder, self).__init__(name = name, **kwargs)\n",
        "    self.layer1 = tf.keras.layers.Dense(units = hidden, activation = 'relu', kernel_initializer = 'random_normal')\n",
        "    self.layer2 = tf.keras.layers.Dense(units = intermediate, activation = 'relu', kernel_initializer = 'random_normal')\n",
        "    self.mu = tf.keras.layers.Dense(units = intermediate, activation = 'relu', kernel_initializer = 'random_normal')\n",
        "    self.sigma = tf.keras.layers.Dense(units = intermediate, activation = 'relu', kernel_initializer = 'random_normal')\n",
        "    self.sample_generator = SampleGenerator()\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.layer1(inputs)\n",
        "    x = self.layer2(x)\n",
        "    mu = self.mu(x)\n",
        "    sigma = self.sigma(x)\n",
        "    z = self.sample_generator((mu, sigma))\n",
        "    return mu, sigma, z\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvuD8ebmnFUe"
      },
      "source": [
        "#Defining a decoder's block. This is a layer-subclassing procedure to recreate the original data/image"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onbRwBTHnSsa"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,original_dim, hidden = 64,intermediate = 128, name = 'decoder', **kwargs):\n",
        "    super(Decoder, self).__init__(name = name, **kwargs)\n",
        "    self.dense1 = tf.keras.layers.Dense(units = hidden, activation = 'relu', kernel_initializer = 'random_normal')\n",
        "    self.dense2 = tf.keras.layers.Dense(units = intermediate, activation = 'relu', kernel_initializer='random_normal')\n",
        "    self.out = tf.keras.layers.Dense(units = original_dim, activation ='sigmoid')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    return self.out(x)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4AB6atkooEy"
      },
      "source": [
        "#The autoencoder's class: (this is a model-subclassing) procedure. Here we combine encoder's and the decoder's to get an end-to-end model"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiCyyquPo53g"
      },
      "source": [
        "class MyAutoEncoder(tf.keras.Model):\n",
        "  def __init__(self, original_dim, hidden = 64, intermediate = 128, name = 'vae', **kwargs):\n",
        "    super(MyAutoEncoder, self).__init__(name = name, **kwargs)\n",
        "    self.original_dim = original_dim\n",
        "    self.encoder = Encoder(hidden = hidden, intermediate = intermediate)\n",
        "    self.decoder = Decoder(original_dim = original_dim, hidden = hidden)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    mu, sigma, z = self.encoder(inputs)\n",
        "    re_build = self.decoder(z)\n",
        "    kl_Div = -0.5 * tf.reduce_mean(sigma - tf.square(mu) - tf.exp(sigma) + 1)\n",
        "    self.add_loss(kl_Div)\n",
        "    return re_build\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMrnv_5CrofW"
      },
      "source": [
        "#Instantiate our model "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GZUUUFmrtr3"
      },
      "source": [
        "original_dim = 784 #This is a flat version of  32,32,3 cifar10 image"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V--U0aVXr4Ap"
      },
      "source": [
        "VAE = MyAutoEncoder(original_dim,64,128)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWroepzxsJN9"
      },
      "source": [
        "#Get the data and pre-process (We only need a training set)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF4ECR-wsXDn",
        "outputId": "496e082f-b859-4be3-a8ae-6d4d895b3871"
      },
      "source": [
        "(x_train, _),(_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZouHHsesm8i",
        "outputId": "2434be9d-7e9e-46cd-d179-2ac335ed925f"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfbzMB6SsrTV"
      },
      "source": [
        "x_train = x_train.reshape(60000,784).astype('float32')/255.0"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8mZUSZotsNV"
      },
      "source": [
        "#Change to tensorflow dataset for easy streaming\n",
        "x_train.shape\n",
        "train_dfm = tf.data.Dataset.from_tensor_slices(x_train)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oomRniPNt8tD"
      },
      "source": [
        "train_dfm = train_dfm.shuffle(buffer_size = 1024).batch(64)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpWxe9O8uKnz"
      },
      "source": [
        "epochs = 10"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMZgtYOcu_If"
      },
      "source": [
        "main_loss = tf.keras.losses.MeanAbsoluteError()\n",
        "metric_fn = tf.keras.metrics.Mean()\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-3)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vbrGMRiuOpZ"
      },
      "source": [
        "#The training loop"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quPa4uBfuRMP",
        "outputId": "6b512717-3098-466f-c441-41b68719832e"
      },
      "source": [
        "tic = time.time()\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Here we begin training at epoch: {epoch}\")\n",
        "\n",
        "  for step, x_batch_train in enumerate(train_dfm):\n",
        "    with tf.GradientTape() as tape:\n",
        "      re_build = VAE(x_batch_train)\n",
        "      loss = main_loss(x_batch_train, re_build)\n",
        "      loss+=sum(VAE.losses)#Adding the KL_Divergence loss for autoencoder\n",
        "    grads = tape.gradient(loss, VAE.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, VAE.trainable_weights))\n",
        "    metric_fn(loss)\n",
        "    if step % 100 == 0:\n",
        "      print(\"step %d: mean loss = %.4f\" % (step, metric_fn.result()))\n",
        "toc = time.time()\n",
        "print(f\"Time elapsed: {time_fmt(tic - toc)}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here we begin training at epoch: 0\n",
            "step 0: mean loss = 0.4745\n",
            "step 100: mean loss = 0.1680\n",
            "step 200: mean loss = 0.1469\n",
            "step 300: mean loss = 0.1395\n",
            "step 400: mean loss = 0.1362\n",
            "step 500: mean loss = 0.1337\n",
            "step 600: mean loss = 0.1323\n",
            "step 700: mean loss = 0.1311\n",
            "step 800: mean loss = 0.1303\n",
            "step 900: mean loss = 0.1295\n",
            "Here we begin training at epoch: 1\n",
            "step 0: mean loss = 0.1293\n",
            "step 100: mean loss = 0.1289\n",
            "step 200: mean loss = 0.1287\n",
            "step 300: mean loss = 0.1283\n",
            "step 400: mean loss = 0.1282\n",
            "step 500: mean loss = 0.1278\n",
            "step 600: mean loss = 0.1277\n",
            "step 700: mean loss = 0.1274\n",
            "step 800: mean loss = 0.1273\n",
            "step 900: mean loss = 0.1271\n",
            "Here we begin training at epoch: 2\n",
            "step 0: mean loss = 0.1270\n",
            "step 100: mean loss = 0.1269\n",
            "step 200: mean loss = 0.1269\n",
            "step 300: mean loss = 0.1267\n",
            "step 400: mean loss = 0.1267\n",
            "step 500: mean loss = 0.1266\n",
            "step 600: mean loss = 0.1265\n",
            "step 700: mean loss = 0.1264\n",
            "step 800: mean loss = 0.1264\n",
            "step 900: mean loss = 0.1262\n",
            "Here we begin training at epoch: 3\n",
            "step 0: mean loss = 0.1262\n",
            "step 100: mean loss = 0.1262\n",
            "step 200: mean loss = 0.1262\n",
            "step 300: mean loss = 0.1261\n",
            "step 400: mean loss = 0.1261\n",
            "step 500: mean loss = 0.1261\n",
            "step 600: mean loss = 0.1260\n",
            "step 700: mean loss = 0.1260\n",
            "step 800: mean loss = 0.1259\n",
            "step 900: mean loss = 0.1259\n",
            "Here we begin training at epoch: 4\n",
            "step 0: mean loss = 0.1258\n",
            "step 100: mean loss = 0.1258\n",
            "step 200: mean loss = 0.1258\n",
            "step 300: mean loss = 0.1258\n",
            "step 400: mean loss = 0.1258\n",
            "step 500: mean loss = 0.1258\n",
            "step 600: mean loss = 0.1257\n",
            "step 700: mean loss = 0.1257\n",
            "step 800: mean loss = 0.1257\n",
            "step 900: mean loss = 0.1256\n",
            "Here we begin training at epoch: 5\n",
            "step 0: mean loss = 0.1256\n",
            "step 100: mean loss = 0.1256\n",
            "step 200: mean loss = 0.1256\n",
            "step 300: mean loss = 0.1256\n",
            "step 400: mean loss = 0.1256\n",
            "step 500: mean loss = 0.1255\n",
            "step 600: mean loss = 0.1255\n",
            "step 700: mean loss = 0.1255\n",
            "step 800: mean loss = 0.1255\n",
            "step 900: mean loss = 0.1255\n",
            "Here we begin training at epoch: 6\n",
            "step 0: mean loss = 0.1254\n",
            "step 100: mean loss = 0.1254\n",
            "step 200: mean loss = 0.1255\n",
            "step 300: mean loss = 0.1254\n",
            "step 400: mean loss = 0.1254\n",
            "step 500: mean loss = 0.1254\n",
            "step 600: mean loss = 0.1254\n",
            "step 700: mean loss = 0.1254\n",
            "step 800: mean loss = 0.1254\n",
            "step 900: mean loss = 0.1253\n",
            "Here we begin training at epoch: 7\n",
            "step 0: mean loss = 0.1253\n",
            "step 100: mean loss = 0.1253\n",
            "step 200: mean loss = 0.1253\n",
            "step 300: mean loss = 0.1253\n",
            "step 400: mean loss = 0.1253\n",
            "step 500: mean loss = 0.1253\n",
            "step 600: mean loss = 0.1253\n",
            "step 700: mean loss = 0.1253\n",
            "step 800: mean loss = 0.1253\n",
            "step 900: mean loss = 0.1253\n",
            "Here we begin training at epoch: 8\n",
            "step 0: mean loss = 0.1252\n",
            "step 100: mean loss = 0.1252\n",
            "step 200: mean loss = 0.1253\n",
            "step 300: mean loss = 0.1252\n",
            "step 400: mean loss = 0.1253\n",
            "step 500: mean loss = 0.1252\n",
            "step 600: mean loss = 0.1252\n",
            "step 700: mean loss = 0.1252\n",
            "step 800: mean loss = 0.1252\n",
            "step 900: mean loss = 0.1252\n",
            "Here we begin training at epoch: 9\n",
            "step 0: mean loss = 0.1252\n",
            "step 100: mean loss = 0.1252\n",
            "step 200: mean loss = 0.1252\n",
            "step 300: mean loss = 0.1252\n",
            "step 400: mean loss = 0.1252\n",
            "step 500: mean loss = 0.1252\n",
            "step 600: mean loss = 0.1252\n",
            "step 700: mean loss = 0.1252\n",
            "step 800: mean loss = 0.1252\n",
            "step 900: mean loss = 0.1251\n",
            "Time elapsed: 0: 56: 39.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW9rbzB-wo-V"
      },
      "source": [
        "#Autoencoder's for cifar10 data"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow54BCoOI4J4"
      },
      "source": [
        "inputs = tf.keras.Input(shape = (32,32,3), name = 'cifar10_img')\n",
        "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'valid')(inputs)\n",
        "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'valid')(x)\n",
        "x = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'valid')(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'valid')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "out = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "x = tf.keras.layers.Reshape((8,8,1))(out)\n",
        "x = tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size = (3,3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (3,3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.UpSampling2D(size = (2,2))(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size = (3,3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (3,3), activation = 'relu')(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (3,3), activation = 'relu')(x)\n",
        "og_img = tf.keras.layers.Conv2DTranspose(filters = 3, kernel_size = (3,3), activation = 'relu', name = 'org_img')(x)\n",
        "vae = tf.keras.Model(inputs = inputs, outputs = og_img)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWo0zgtgNC86",
        "outputId": "e4afe084-d01e-4627-ae8f-87079c606f4e"
      },
      "source": [
        "vae.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cifar10_img (InputLayer)     [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 28, 28, 64)        73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 10, 10, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_8 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 8, 8, 1)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_20 (Conv2DT (None, 10, 10, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_21 (Conv2DT (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_22 (Conv2DT (None, 26, 26, 64)        73792     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_23 (Conv2DT (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_24 (Conv2DT (None, 30, 30, 128)       147584    \n",
            "_________________________________________________________________\n",
            "org_img (Conv2DTranspose)    (None, 32, 32, 3)         3459      \n",
            "=================================================================\n",
            "Total params: 598,467\n",
            "Trainable params: 598,339\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av_lSk9qPHcm"
      },
      "source": [
        "my_loss = tf.keras.losses.MeanAbsoluteError()\n",
        "my_metric = tf.keras.metrics.Mean()\n",
        "my_optimizer = tf.keras.optimizers.RMSprop(learning_rate = 1e-3)\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVe2fz4EQV9c"
      },
      "source": [
        "epochs = 15"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1lL9p0rQxBa"
      },
      "source": [
        "#Load cifar10 dataset\n",
        "(x_train, _),(_, _) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW42lQzoRB14"
      },
      "source": [
        "#Preprocess the data and convert to tensorflow datatype in batches of size 64 each\n",
        "x_train = x_train.astype('float32')/255.0"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi1QQR15Rbxc",
        "outputId": "c2d099e2-1dc8-4e81-e800-7af25f3aa45a"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq5_9JkLRf95"
      },
      "source": [
        "train_dfm = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "train_dfm = train_dfm.shuffle(buffer_size = 1024).batch(64)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXWxNBgTQZoO",
        "outputId": "e0de4101-5b0b-4389-9852-a27ea80354ad"
      },
      "source": [
        "tic = time.time()\n",
        "for epoch in range(epochs):\n",
        "  print(f\"The start of epoch: {epoch}\")\n",
        "  for step,x_train_batch in enumerate(train_dfm):\n",
        "    with tf.GradientTape() as tape:\n",
        "      org_img = vae(x_train_batch)\n",
        "      loss = my_loss(x_train_batch, org_img)\n",
        "      loss+= loss\n",
        "    grads = tape.gradient(loss, vae.trainable_weights)\n",
        "    my_optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "    my_metric(loss)\n",
        "    if step % 100 == 0:\n",
        "      print(\"step %d: mean loss = %.4f\" % (step, my_metric.result()))\n",
        "toc = time.time()\n",
        "print(f\"time elapsed: {tic - toc}\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The start of epoch: 0\n",
            "step 0: mean loss = 0.9166\n",
            "step 100: mean loss = 0.5413\n",
            "step 200: mean loss = 0.4840\n",
            "step 300: mean loss = 0.4627\n",
            "step 400: mean loss = 0.4515\n",
            "step 500: mean loss = 0.4424\n",
            "step 600: mean loss = 0.4344\n",
            "step 700: mean loss = 0.4257\n",
            "The start of epoch: 1\n",
            "step 0: mean loss = 0.4190\n",
            "step 100: mean loss = 0.4120\n",
            "step 200: mean loss = 0.4059\n",
            "step 300: mean loss = 0.4003\n",
            "step 400: mean loss = 0.3949\n",
            "step 500: mean loss = 0.3904\n",
            "step 600: mean loss = 0.3860\n",
            "step 700: mean loss = 0.3821\n",
            "The start of epoch: 2\n",
            "step 0: mean loss = 0.3789\n",
            "step 100: mean loss = 0.3755\n",
            "step 200: mean loss = 0.3723\n",
            "step 300: mean loss = 0.3694\n",
            "step 400: mean loss = 0.3666\n",
            "step 500: mean loss = 0.3641\n",
            "step 600: mean loss = 0.3616\n",
            "step 700: mean loss = 0.3593\n",
            "The start of epoch: 3\n",
            "step 0: mean loss = 0.3574\n",
            "step 100: mean loss = 0.3552\n",
            "step 200: mean loss = 0.3531\n",
            "step 300: mean loss = 0.3513\n",
            "step 400: mean loss = 0.3494\n",
            "step 500: mean loss = 0.3477\n",
            "step 600: mean loss = 0.3459\n",
            "step 700: mean loss = 0.3443\n",
            "The start of epoch: 4\n",
            "step 0: mean loss = 0.3429\n",
            "step 100: mean loss = 0.3413\n",
            "step 200: mean loss = 0.3399\n",
            "step 300: mean loss = 0.3385\n",
            "step 400: mean loss = 0.3371\n",
            "step 500: mean loss = 0.3358\n",
            "step 600: mean loss = 0.3345\n",
            "step 700: mean loss = 0.3332\n",
            "The start of epoch: 5\n",
            "step 0: mean loss = 0.3322\n",
            "step 100: mean loss = 0.3310\n",
            "step 200: mean loss = 0.3298\n",
            "step 300: mean loss = 0.3288\n",
            "step 400: mean loss = 0.3277\n",
            "step 500: mean loss = 0.3266\n",
            "step 600: mean loss = 0.3256\n",
            "step 700: mean loss = 0.3246\n",
            "The start of epoch: 6\n",
            "step 0: mean loss = 0.3238\n",
            "step 100: mean loss = 0.3228\n",
            "step 200: mean loss = 0.3218\n",
            "step 300: mean loss = 0.3210\n",
            "step 400: mean loss = 0.3201\n",
            "step 500: mean loss = 0.3192\n",
            "step 600: mean loss = 0.3184\n",
            "step 700: mean loss = 0.3176\n",
            "The start of epoch: 7\n",
            "step 0: mean loss = 0.3169\n",
            "step 100: mean loss = 0.3161\n",
            "step 200: mean loss = 0.3153\n",
            "step 300: mean loss = 0.3145\n",
            "step 400: mean loss = 0.3138\n",
            "step 500: mean loss = 0.3131\n",
            "step 600: mean loss = 0.3123\n",
            "step 700: mean loss = 0.3116\n",
            "The start of epoch: 8\n",
            "step 0: mean loss = 0.3110\n",
            "step 100: mean loss = 0.3104\n",
            "step 200: mean loss = 0.3097\n",
            "step 300: mean loss = 0.3091\n",
            "step 400: mean loss = 0.3084\n",
            "step 500: mean loss = 0.3078\n",
            "step 600: mean loss = 0.3072\n",
            "step 700: mean loss = 0.3066\n",
            "The start of epoch: 9\n",
            "step 0: mean loss = 0.3060\n",
            "step 100: mean loss = 0.3055\n",
            "step 200: mean loss = 0.3049\n",
            "step 300: mean loss = 0.3043\n",
            "step 400: mean loss = 0.3038\n",
            "step 500: mean loss = 0.3032\n",
            "step 600: mean loss = 0.3027\n",
            "step 700: mean loss = 0.3022\n",
            "The start of epoch: 10\n",
            "step 0: mean loss = 0.3017\n",
            "step 100: mean loss = 0.3012\n",
            "step 200: mean loss = 0.3007\n",
            "step 300: mean loss = 0.3002\n",
            "step 400: mean loss = 0.2997\n",
            "step 500: mean loss = 0.2992\n",
            "step 600: mean loss = 0.2987\n",
            "step 700: mean loss = 0.2983\n",
            "The start of epoch: 11\n",
            "step 0: mean loss = 0.2979\n",
            "step 100: mean loss = 0.2974\n",
            "step 200: mean loss = 0.2970\n",
            "step 300: mean loss = 0.2965\n",
            "step 400: mean loss = 0.2961\n",
            "step 500: mean loss = 0.2957\n",
            "step 600: mean loss = 0.2952\n",
            "step 700: mean loss = 0.2948\n",
            "The start of epoch: 12\n",
            "step 0: mean loss = 0.2945\n",
            "step 100: mean loss = 0.2940\n",
            "step 200: mean loss = 0.2936\n",
            "step 300: mean loss = 0.2933\n",
            "step 400: mean loss = 0.2929\n",
            "step 500: mean loss = 0.2925\n",
            "step 600: mean loss = 0.2921\n",
            "step 700: mean loss = 0.2917\n",
            "The start of epoch: 13\n",
            "step 0: mean loss = 0.2914\n",
            "step 100: mean loss = 0.2910\n",
            "step 200: mean loss = 0.2907\n",
            "step 300: mean loss = 0.2903\n",
            "step 400: mean loss = 0.2900\n",
            "step 500: mean loss = 0.2896\n",
            "step 600: mean loss = 0.2893\n",
            "step 700: mean loss = 0.2889\n",
            "The start of epoch: 14\n",
            "step 0: mean loss = 0.2886\n",
            "step 100: mean loss = 0.2883\n",
            "step 200: mean loss = 0.2880\n",
            "step 300: mean loss = 0.2877\n",
            "step 400: mean loss = 0.2873\n",
            "step 500: mean loss = 0.2870\n",
            "step 600: mean loss = 0.2867\n",
            "step 700: mean loss = 0.2864\n",
            "time elapsed: -452.43489956855774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slg-cBsLbgVt",
        "outputId": "dd553292-14e9-4fb0-cbf1-2168d2441b06"
      },
      "source": [
        "print(f\"time elapsed: {time_fmt(toc - tic)}\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time elapsed: 0: 07: 32.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AwgMbq6T_s4"
      },
      "source": [
        "#Transfers weights between layers/models in memory"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOMB0zn5hwoj"
      },
      "source": [
        "def create_layer():\n",
        "  dense1 = tf.keras.layers.Dense(units = 128, kernel_initializer = 'random_normal', activation = 'relu')\n",
        "  dense1.build((None, 10))\n",
        "  return dense1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg60fwlZiXc0"
      },
      "source": [
        "layer1 = create_layer()\n",
        "layer2 = create_layer()\n",
        "#Copy the weights of layer2 into layer1 in memory"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "algS7e8AilfT"
      },
      "source": [
        "layer1.set_weights(layer2.get_weights())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHLDSY_2i3NK",
        "outputId": "cf537258-cf82-439a-87d8-165caf125393"
      },
      "source": [
        "layer1.weights"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'kernel:0' shape=(10, 128) dtype=float32, numpy=\n",
              " array([[ 0.01219196,  0.01521388,  0.0172997 , ...,  0.00185943,\n",
              "          0.07479358,  0.09444313],\n",
              "        [-0.04293034, -0.05951702,  0.10514595, ...,  0.02156232,\n",
              "         -0.04493762,  0.02061929],\n",
              "        [ 0.04145955,  0.00827649, -0.03990454, ...,  0.04628895,\n",
              "         -0.0167529 , -0.03513458],\n",
              "        ...,\n",
              "        [-0.00223408,  0.02422469, -0.07955934, ..., -0.03633394,\n",
              "          0.01366639,  0.04751098],\n",
              "        [-0.05802162,  0.00649976,  0.0043287 , ...,  0.04398169,\n",
              "         -0.05317219, -0.00212604],\n",
              "        [-0.02682946,  0.0966531 ,  0.01498333, ...,  0.08006915,\n",
              "         -0.00735555,  0.01209113]], dtype=float32)>,\n",
              " <tf.Variable 'bias:0' shape=(128,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ontssci6Go"
      },
      "source": [
        "class MLP(tf.keras.layers.Layer):\n",
        "  def __init__(self, units = 64, name = 'mlp', **kwargs):\n",
        "    super(MLP, self).__init__(name = name, **kwargs)\n",
        "    self.units = units\n",
        "    self.dense1 = tf.keras.layers.Dense(units = 64, activation = 'relu', kernel_initializer = 'random_normal')\n",
        "    self.out = tf.keras.layers.Dense(units = 10, activation = 'softmax')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    return self.out(x)\n",
        "\n",
        "mlp = MLP(64)\n",
        "inputs = tf.keras.Input(shape = (10,))\n",
        "out = mlp(inputs)\n",
        "model1 = tf.keras.Model(inputs = inputs, outputs = out, name = 'mlp1')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3OVd7Ldm4dE"
      },
      "source": [
        "x = tf.keras.layers.Dense(units = 64, kernel_initializer = 'random_normal', activation = 'relu')(inputs)\n",
        "outputs = tf.keras.layers.Dense(units = 10, activation = 'softmax')(x)\n",
        "model2 = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'mlp2')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haoRcO8RrNXb",
        "outputId": "6ec1d335-d26f-4f98-e44b-74c3c6774251"
      },
      "source": [
        "model1.summary()\n",
        "model2.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mlp1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "mlp (MLP)                    (None, 10)                1354      \n",
            "=================================================================\n",
            "Total params: 1,354\n",
            "Trainable params: 1,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"mlp2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,354\n",
            "Trainable params: 1,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVWueBKNrU3e"
      },
      "source": [
        "class MLP(tf.keras.Model):\n",
        "  def __init__(self, name = 'mlp', **kwargs):\n",
        "    super(MLP, self).__init__(name = name, **kwargs)\n",
        "    self.dense1 = tf.keras.layers.Dense(units = 64, kernel_initializer = 'random_normal', activation = 'relu')\n",
        "    self.dense2 = tf.keras.layers.Dense(units = 10, activation = 'softmax')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    return self.dense2(x)\n",
        "\n",
        "mlp3 = MLP('mlp')\n",
        "x = tf.keras.Input(shape = (10,))\n",
        "out = mlp3(x)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPDEtZJ1t057"
      },
      "source": [
        "model3 = tf.keras.Model(inputs = x, outputs = out, name = 'mlp3')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpkTdqB4vvVh",
        "outputId": "fc4bace4-be26-4921-9053-59c2745b5753"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mlp2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,354\n",
            "Trainable params: 1,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSiYgMYyv6ym",
        "outputId": "ef1e7801-c414-4825-c8f3-7bc737554b74"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mlp2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                704       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 1,354\n",
            "Trainable params: 1,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we4hLw84wE2e"
      },
      "source": [
        "#Model2 and model3 are similar. We may copy the weights of model2 into model 3"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zm4D44MwOoj"
      },
      "source": [
        "model3.set_weights(model2.get_weights())"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNPruiwbwVfz",
        "outputId": "c6f3b2ff-2953-4e7d-ba28-e6ff4706b3f8"
      },
      "source": [
        "model3.weights[0][0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
              "array([-0.01534462, -0.05064329,  0.02400648, -0.00213329, -0.00823203,\n",
              "        0.05355125, -0.02436385,  0.01666885, -0.04729612,  0.04052295,\n",
              "        0.06036309,  0.04915816, -0.06656834, -0.0058924 , -0.0437604 ,\n",
              "       -0.00790327,  0.11943638, -0.01702216, -0.01630173, -0.04385459,\n",
              "        0.00697704,  0.01312253,  0.04664024, -0.10954863, -0.05228733,\n",
              "       -0.03052824, -0.04021033,  0.06932499, -0.00365266, -0.03061824,\n",
              "        0.03948629,  0.00508403, -0.01892553,  0.06346243, -0.01796403,\n",
              "       -0.01961886, -0.05609553,  0.01803293,  0.0006699 , -0.01407005,\n",
              "        0.04398337,  0.01187514,  0.07431163, -0.01178166,  0.04493083,\n",
              "       -0.04839073, -0.08507457, -0.00264564,  0.01973548, -0.02368109,\n",
              "        0.06850316, -0.04140654,  0.056061  , -0.02159815, -0.07319919,\n",
              "       -0.00670119,  0.0623123 ,  0.04325527,  0.0854376 , -0.03789325,\n",
              "       -0.08378753, -0.06424625, -0.02531073,  0.01734059], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9J98cIgwX2D",
        "outputId": "349c1e22-8616-47a2-a49a-45dc1cd9a322"
      },
      "source": [
        "model2.weights[0][0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
              "array([-0.01534462, -0.05064329,  0.02400648, -0.00213329, -0.00823203,\n",
              "        0.05355125, -0.02436385,  0.01666885, -0.04729612,  0.04052295,\n",
              "        0.06036309,  0.04915816, -0.06656834, -0.0058924 , -0.0437604 ,\n",
              "       -0.00790327,  0.11943638, -0.01702216, -0.01630173, -0.04385459,\n",
              "        0.00697704,  0.01312253,  0.04664024, -0.10954863, -0.05228733,\n",
              "       -0.03052824, -0.04021033,  0.06932499, -0.00365266, -0.03061824,\n",
              "        0.03948629,  0.00508403, -0.01892553,  0.06346243, -0.01796403,\n",
              "       -0.01961886, -0.05609553,  0.01803293,  0.0006699 , -0.01407005,\n",
              "        0.04398337,  0.01187514,  0.07431163, -0.01178166,  0.04493083,\n",
              "       -0.04839073, -0.08507457, -0.00264564,  0.01973548, -0.02368109,\n",
              "        0.06850316, -0.04140654,  0.056061  , -0.02159815, -0.07319919,\n",
              "       -0.00670119,  0.0623123 ,  0.04325527,  0.0854376 , -0.03789325,\n",
              "       -0.08378753, -0.06424625, -0.02531073,  0.01734059], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C60IXh7lwl-s"
      },
      "source": [
        "#Weight transfer from one model to the other"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NeMaN_0rU_w"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVa0HRD5rYXk"
      },
      "source": [
        "class NewMLP(tf.keras.Model):\n",
        "  def __init__(self, name = 'new_mlp', **kwargs):\n",
        "    super(NewMLP, self).__init__(name = name, **kwargs)\n",
        "    self.dense1 = tf.keras.layers.Dense(units = 128, kernel_initializer = 'random_normal', activation = 'relu')\n",
        "    self.dense2 = tf.keras.layers.Dense(units = 64, kernel_initializer = 'random_normal', activation = 'relu')\n",
        "    self.out = tf.keras.layers.Dense(units = 10, activation = 'softmax')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    return self.out(x)\n",
        "\n",
        "mlp = NewMLP('new_mlp')\n",
        "inputs = tf.keras.Input(shape = (10,))\n",
        "outputs = mlp(inputs)\n",
        "model_new = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'new_mlp')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ0qzVk1tQ33"
      },
      "source": [
        "#Now doing the transfers of the weights to a new model\n",
        "trans_new = tf.keras.Model(inputs = model_new.input, outputs = model_new.layers[-1].input, name = 'mlp_transfer')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok-OQ38ut3tu",
        "outputId": "440b7d6a-1e06-4e4b-861f-3855573cd4fc"
      },
      "source": [
        "model_new.summary()\n",
        "trans_new.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"new_mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "new_mlp (NewMLP)             (None, 10)                10314     \n",
            "=================================================================\n",
            "Total params: 10,314\n",
            "Trainable params: 10,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"mlp_transfer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 10)]              0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9GbQXwot859"
      },
      "source": [
        "#We assign weights to our new model as follows:\n",
        "for W in trans_new.weights:\n",
        "  W.assign(tf.random_normal(W.shape))\n",
        "  trans_new.save_weights('my_weights')\n",
        "  trans_new.summary()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M59qEvimuv4n"
      },
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyJvy4MiblCv"
      },
      "source": [
        "dfm = np.array([[1.2,2.3,2.1],[2.3,4.2,1.5],[4.2,4.5,1.4]])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZS14WQ3b7uC"
      },
      "source": [
        "normalize = preprocessing.Normalization()\n",
        "normalize.adapt(dfm)\n",
        "dfm_norm = normalize(dfm)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHdHm98kcVA5",
        "outputId": "35bb25b8-421e-4024-8e6f-f09e042da7c0"
      },
      "source": [
        "dfm"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2, 2.3, 2.1],\n",
              "       [2.3, 4.2, 1.5],\n",
              "       [4.2, 4.5, 1.4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S8v2D7WcbaV",
        "outputId": "6908d63b-26c2-485b-e4cd-f730989450cd"
      },
      "source": [
        "dfm_norm"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[-1.1028839 , -1.4029912 ,  1.4018258 ],\n",
              "       [-0.21519688,  0.5475084 , -0.5391637 ],\n",
              "       [ 1.3180808 ,  0.8554823 , -0.86266214]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e12bEW0UcdE1",
        "outputId": "6f0cc34c-182e-4b6f-dc71-2c319f9b221d"
      },
      "source": [
        "print(f\"normalized mean: {dfm_norm.numpy().mean():.2f}\\nnormalized std: {dfm_norm.numpy().std():.2f}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normalized mean: -0.00\n",
            "normalized std: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EiRBIPrdp0A"
      },
      "source": [
        "#Text vectorization"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZtSsgKyiw2v"
      },
      "source": [
        "layer = preprocessing.TextVectorization()\n",
        "data = ['Mama anapika', 'ugali na samaki ','halafu wewe', 'usiniletee' ,'mambo ya kiboya']"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSOhols7jFqP"
      },
      "source": [
        "layer.adapt(data = data)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoAxL5uxjMpI"
      },
      "source": [
        "token_data = layer(data)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGCJ-bY_jUOR",
        "outputId": "22d807ed-3a7d-488d-9395-45fab5f9be6c"
      },
      "source": [
        "token_data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 3), dtype=int64, numpy=\n",
              "array([[ 9, 12,  0],\n",
              "       [ 5,  7,  6],\n",
              "       [11,  3,  0],\n",
              "       [ 4,  0,  0],\n",
              "       [ 8,  2, 10]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP1YtMgdjWIP"
      },
      "source": [
        "#Data augumentantion. Lets perfom some data augumentantion procedures on images"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKidTbCQvM9O"
      },
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqVe10z-vlJR"
      },
      "source": [
        "inputs_dim = (32,32,3) # cifar10 images for example"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlOUETxGvuwh"
      },
      "source": [
        "num_classes = 10"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Tf80b9vylT"
      },
      "source": [
        "inputs = tf.keras.Input(shape = inputs_dim, name = 'cifar10_img')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXSIO5_Rv_5m"
      },
      "source": [
        "dfm_augumentantion = tf.keras.models.Sequential([\n",
        "                                                 preprocessing.RandomZoom(height_factor=0.1),\n",
        "                                                 preprocessing.RandomFlip(mode = 'horizontal'),\n",
        "                                                 preprocessing.RandomRotation(factor = 0.1),\n",
        "                                                 preprocessing.RandomContrast(factor = 0.25)\n",
        "])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B515XSCUxBDt"
      },
      "source": [
        "aug_dfm = dfm_augumentantion(inputs) #Perform the data augumentantion by modify each image according to the specifications\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG1r-Phqx6Rt"
      },
      "source": [
        "#We can rescale the data into (0, 1) for easy training"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Iljh26GzbeY"
      },
      "source": [
        "aug_dfm = preprocessing.Rescaling(1.0/255)(aug_dfm)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-CkgKX2zpyr"
      },
      "source": [
        "#Build a Transfer learning model"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uND0oX_n0B88"
      },
      "source": [
        "outputs = tf.keras.applications.ResNet50(weights=None,input_shape=inputs_dim, classes= num_classes)(aug_dfm)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-bxNNav0iWP"
      },
      "source": [
        "model = tf.keras.Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM0SUBBh1Mev",
        "outputId": "2339b32b-6c66-4451-8f59-b1b73a8c919d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cifar10_img (InputLayer)     [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "sequential_5 (Sequential)    (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "rescaling_2 (Rescaling)      (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, 10)                23608202  \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUJpHNVw11dO"
      },
      "source": [
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "metric_fn = tf.keras.metrics.CategoricalAccuracy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODjsUtX93Oxi"
      },
      "source": [
        "epochs = 10"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRDL9CPJ3Rk-",
        "outputId": "a93b5a42-26be-49bf-98bd-be10b46fe5b7"
      },
      "source": [
        "(x_train,y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZP2zNkZ5oMB",
        "outputId": "f41b3fdb-a4e1-4290-b4e0-8b23e0d87cd5"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dxTftOP6J30"
      },
      "source": [
        "(y_train, y_test) = tf.keras.utils.to_categorical(y_train, num_classes= 10), tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co8U46Hu5yAE"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14dz4lF56hun"
      },
      "source": [
        "train_data = train_data.shuffle(buffer_size = 1024).batch(64)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5nSi4NG6rJP"
      },
      "source": [
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8pqF5fb-A0Q"
      },
      "source": [
        "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJNkY7xZ9DHF",
        "outputId": "72f2a6be-cf26-4282-ea56-0bedc80d8e07"
      },
      "source": [
        "model.fit(x_train, y_train, epochs = epochs, validation_split=0.1, verbose = 2)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 - 64s - loss: 2.3292 - accuracy: 0.2887 - val_loss: 3.5653 - val_accuracy: 0.2904\n",
            "Epoch 2/10\n",
            "1407/1407 - 51s - loss: 2.0652 - accuracy: 0.3503 - val_loss: 2.1050 - val_accuracy: 0.2508\n",
            "Epoch 3/10\n",
            "1407/1407 - 51s - loss: 1.8870 - accuracy: 0.3854 - val_loss: 2.8982 - val_accuracy: 0.4098\n",
            "Epoch 4/10\n",
            "1407/1407 - 51s - loss: 1.8405 - accuracy: 0.4125 - val_loss: 195.1792 - val_accuracy: 0.1030\n",
            "Epoch 5/10\n",
            "1407/1407 - 51s - loss: 2.1305 - accuracy: 0.3009 - val_loss: 1.7792 - val_accuracy: 0.3596\n",
            "Epoch 6/10\n",
            "1407/1407 - 51s - loss: 1.9507 - accuracy: 0.3448 - val_loss: 2.5808 - val_accuracy: 0.4162\n",
            "Epoch 7/10\n",
            "1407/1407 - 51s - loss: 1.8308 - accuracy: 0.3886 - val_loss: 53.9608 - val_accuracy: 0.1434\n",
            "Epoch 8/10\n",
            "1407/1407 - 51s - loss: 1.8710 - accuracy: 0.3697 - val_loss: 2.7431 - val_accuracy: 0.4096\n",
            "Epoch 9/10\n",
            "1407/1407 - 51s - loss: 1.7813 - accuracy: 0.3933 - val_loss: 2.3260 - val_accuracy: 0.4120\n",
            "Epoch 10/10\n",
            "1407/1407 - 51s - loss: 1.6300 - accuracy: 0.4356 - val_loss: 1.5126 - val_accuracy: 0.4712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efe07292668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJCa5btz-PNB"
      },
      "source": [
        "#Text preprocessing for sequence model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mYxpKzuTgdV"
      },
      "source": [
        "texts = tf.constant([\n",
        "                     'Love is always a wonderful thing ever existed',\n",
        "                     'Bob always sings love songs',\n",
        "                     'But it is difficult to find the true love',\n",
        "                     'Too much love can damage your heart once its gone',\n",
        "                     'It is so romantic to be loved by someone you real love',\n",
        "                     'Unfortunately I have an iron heart to trust a woman'\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QuzxLDWUgjt"
      },
      "source": [
        "text_enc = preprocessing.TextVectorization(output_mode='int')\n",
        "text_enc.adapt(texts)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jctEfOCDVGqF"
      },
      "source": [
        "my_voc_list = text_enc.get_vocabulary()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FT3FVdXVYjf",
        "outputId": "da36fb21-309e-4f3b-a0cc-c915ee1ea7d6"
      },
      "source": [
        "print(\"Vocubulary:\", my_voc_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocubulary: ['', '[UNK]', 'love', 'to', 'is', 'it', 'heart', 'always', 'a', 'your', 'you', 'wonderful', 'woman', 'unfortunately', 'trust', 'true', 'too', 'thing', 'the', 'songs', 'someone', 'so', 'sings', 'romantic', 'real', 'once', 'much', 'loved', 'its', 'iron', 'i', 'have', 'gone', 'find', 'existed', 'ever', 'difficult', 'damage', 'can', 'by', 'but', 'bob', 'be', 'an']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFDfTieOWDne"
      },
      "source": [
        "#Building a keras model:\n",
        "inputs = tf.keras.Input(shape = (1,),dtype = 'string')\n",
        "x = text_enc(inputs)\n",
        "x = tf.keras.layers.Embedding(input_dim= len(my_voc_list), output_dim = 32)(x)\n",
        "outputs = tf.keras.layers.LSTM(units = 1)(x)\n",
        "model = tf.keras.Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGDRqEmJXgYE",
        "outputId": "54b8bdf2-89a9-4cd6-989a-d421a177d67c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, None)              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 32)          1408      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 1)                 136       \n",
            "=================================================================\n",
            "Total params: 1,544\n",
            "Trainable params: 1,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj25ypQhYNmh"
      },
      "source": [
        "#Model subclassing to control what happens in the training step (the fit() method)\n",
        "#We may want to customize the fit method to suit our need"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsWUUraq19ln"
      },
      "source": [
        "class MyCustom(tf.keras.Model):\n",
        "  def train_step(self, data):\n",
        "    x, y = data #unpack the data (this may be a numpy arrays tupple or a tf.dataset format)\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(x, training = True)\n",
        "      loss = self.compiled_loss(y, y_pred, regularization_losses = self.losses)\n",
        "    trainable_vars = self.trainable_variables\n",
        "    grads = tape.gradient(loss, trainable_vars)\n",
        "    self.optimizer.apply_gradients(zip(grads, trainable_vars))\n",
        "    self.compiled_metrics.update_state(y, y_pred)\n",
        "    return {k.name:k.result() for k in self.metrics}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8CGiRUs4bfV"
      },
      "source": [
        "#The simple model by applying the above customized training step"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KScg8H2o4jnE"
      },
      "source": [
        "inputs = tf.keras.Input(shape = (32,))\n",
        "x = tf.keras.layers.Dense(units =128, activation = 'relu', kernel_initializer = 'random_normal')(inputs)\n",
        "x = tf.keras.layers.Dense(units = 64, activation ='relu', kernel_initializer = 'random_normal')(x)\n",
        "outputs = tf.keras.layers.Dense(units = 10, activation = 'softmax')(x)\n",
        "model = MyCustom(inputs, outputs)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd3htiqh5suW",
        "outputId": "b3a93ca4-ce32-4f5a-fb36-64a58c2f0da8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_custom_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               4224      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 13,130\n",
            "Trainable params: 13,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNDIzZP-7Bje"
      },
      "source": [
        "#Test the model with some fake data"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M32BFPyi7Pbb"
      },
      "source": [
        "x, y = np.random.random(size = (100, 32)), np.random.random(size = (100, 10))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tFo6s7x8mXI"
      },
      "source": [
        "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = 'accuracy')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8dBXRhh77Tj",
        "outputId": "a2de447a-43a8-42c4-9b14-b0f426595d8f"
      },
      "source": [
        "model.fit(x,y, epochs = 3)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "4/4 [==============================] - 2s 4ms/step - loss: 11.6840 - accuracy: 0.0707\n",
            "Epoch 2/3\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 11.7261 - accuracy: 0.0368\n",
            "Epoch 3/3\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 11.6439 - accuracy: 0.0584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7493bda198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6AGLuYp8hEx"
      },
      "source": [
        "#Customized fit() method with labels/class  priority using sample_weights (for regression) or class weights (for classificaton)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBNzdJOX4Mjg"
      },
      "source": [
        "class MyCustomFit(tf.keras.Model):\n",
        "  def train_step(self, data):\n",
        "    if len(data)==3:\n",
        "      x, y, sample_weight = data\n",
        "    else:\n",
        "      x,y = data #unpacking the data\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(x,training = True)\n",
        "      loss = self.compiled_loss(y, y_pred, sample_weight = sample_weight, regularization_losses = self.losses)\n",
        "    trainable_vars = self.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "    self.compiled_metrics.update_state(y, y_pred,sample_weight = sample_weight)\n",
        "    return {k.name : k.result() for k in self.metrics}\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enQCeqHY7Big"
      },
      "source": [
        "#Build a simple mlp and fit as ussual but the above customization will be used"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Iw_jIhw7Tv8"
      },
      "source": [
        "inputs = tf.keras.Input(shape = (64, ))\n",
        "x = tf.keras.layers.Dense(units = 128, activation = 'relu', kernel_initializer = 'random_normal')(inputs)\n",
        "x = tf.keras.layers.Dense(units = 64, activation = 'relu', kernel_initializer = 'random_normal')(x)\n",
        "outputs = tf.keras.layers.Dense(units = 1)(x)\n",
        "model = MyCustomFit(inputs, outputs, name = 'mlp')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ucttJFf8fHx",
        "outputId": "f4a6aac6-d3f5-4caa-ec57-6658c0da3a82"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 16,641\n",
            "Trainable params: 16,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFyPjJZL8hVW"
      },
      "source": [
        "x = np.random.random(size = (100, 64))\n",
        "y = np.random.random(size = (100, 1))\n",
        "s_wt = np.random.random(size = (100,1))\n",
        "model.compile(optimizer = 'RMSprop', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGEOxW7q96E5",
        "outputId": "8949d1fa-cf31-4514-b92a-c5bd1cebc55e"
      },
      "source": [
        "model.fit(x,y, sample_weight=s_wt, epochs = 1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 3.1678e-08 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8b7811b278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYnW8fuw-GBW"
      },
      "source": [
        "#A custumized evaluation step can also be constructed to suit a user's requirements"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nnpfk97oIeaD"
      },
      "source": [
        "#We use model subclassing just like in the training-step we define our own test_step"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPCH8W1yIpBS"
      },
      "source": [
        "class MyEval(tf.keras.Model):\n",
        "  def test_step(self, data):\n",
        "    if len(data) == 3:\n",
        "      x, y, sample_weight = data\n",
        "    else:\n",
        "      x, y = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(x, training = True)#Foward pass to get the predictions\n",
        "      loss = self.compiled_loss(y_pred, y, sample_weight = sample_weight, regularization_losses = self.losses)\n",
        "    trainable_vars = self.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "    self.compiled_metrics.update_state(y, y_pred, sample_weight = sample_weight)\n",
        "    return {k.name : k.result() for k in self.metrics}"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TgfpEgWKx_k"
      },
      "source": [
        "#Using the above we build the testing model as follow "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mNPO0W2LA4s"
      },
      "source": [
        "inputs = tf.keras.Input(shape = (10,))\n",
        "outputs = tf.keras.layers.Dense(units = 1)(inputs)\n",
        "model = MyEval(inputs = inputs, outputs = outputs, name = 'eval_mlp')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL5afs6VLXB_",
        "outputId": "7f9dd766-bd90-4cc5-a46c-41d8252591e9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"eval_mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 11\n",
            "Trainable params: 11\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXpfa6DRLeuh"
      },
      "source": [
        "x = np.random.random(size = (100, 10))\n",
        "y = np.random.random(size = (100,1))\n",
        "s_wt = np.random.random(size = (100,1))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsLyNwLAL1rB"
      },
      "source": [
        "model.compile(loss = 'mse', metrics = ['mae'])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c80Q0okIMRzT",
        "outputId": "a83f14b8-c988-452c-c68b-be05251f43a0"
      },
      "source": [
        "model.evaluate(x, y, sample_weight=s_wt)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1141 - mae: 0.4126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11587373912334442, 0.41385841369628906]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfXo2qbaMXNy"
      },
      "source": [
        "#Generative Adversarial Network from end to end with customized training step:\n",
        "#GAN has two parts like any other encoder's decoder's models\n",
        "#First we have a generator ( this generate fake data (images for example))\n",
        "#Second we have a discriminator that try to classify if the data is fake or real\n",
        "#We have two optimizers for each generator and discriminator but one loss function because only the discriminator get trained"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvh7ClnpcwPl"
      },
      "source": [
        "#GAN-the discriminator (takes input as an image (lets say a 32, 32,3), image)\n",
        "class Discriminator(tf.keras.layers.Layer):\n",
        "  def __init__(self, name = 'discriminator', **kwargs):\n",
        "    super(Discriminator, self).__init__(name = name, **kwargs)\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),\n",
        "                                        strides = (2,2), padding = 'same',\n",
        "                                        activation = tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3),\n",
        "                                        activation = tf.keras.layers.LeakyReLU(alpha = 0.2),\n",
        "                                        strides = (2,2), padding = 'same')\n",
        "    self.bn = tf.keras.layers.BatchNormalization()\n",
        "    self.maxpool = tf.keras.layers.MaxPooling2D(pool_size = (2,2))\n",
        "    self.conv3 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), strides = (2,2),\n",
        "                                        activation = tf.keras.layers.LeakyReLU(alpha = 0.2), padding = 'same')\n",
        "    self.conv4 = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3),\n",
        "                                        strides = (2,2), padding = 'same',\n",
        "                                        activation = tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
        "    self.glb = tf.keras.layers.GlobalMaxPool2D()\n",
        "    self.classify = tf.keras.layers.Dense(units = 1)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.glb(x)\n",
        "    return self.classify(x)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrJLDdXiiZrB"
      },
      "source": [
        "discriminator = Discriminator(name = 'discriminator')\n",
        "inputs = tf.keras.Input(shape = (32,32,3))\n",
        "outputs = discriminator(inputs)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO90mdYinSYK"
      },
      "source": [
        "model1 = tf.keras.Model(inputs = inputs, outputs = outputs, name = 'discriminator')"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "fyIB46Ryoj4T",
        "outputId": "cde46e0c-d055-445a-d2b7-44fdfe3b4c03"
      },
      "source": [
        "model1.summary()\n",
        "tf.keras.utils.plot_model(model = model1, to_file = 'discriminator.png', show_shapes = True)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "discriminator (Discriminator (None, 1)                 225345    \n",
            "=================================================================\n",
            "Total params: 225,345\n",
            "Trainable params: 225,217\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z42YIChyzSIS",
        "outputId": "fcc9460c-434b-48ef-ed1b-c06517f1a28f"
      },
      "source": [
        "model_fn.summary()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cnn_fn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 16, 16, 128)       3584      \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 8, 8, 64)          73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 2, 2, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 1, 1, 64)          73792     \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_7 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 225,345\n",
            "Trainable params: 225,217\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiGBP27_1-Lb"
      },
      "source": [
        "class Generator(tf.keras.layers.Layer):\n",
        "  def __init__(self, name = 'generator', **kwargs):\n",
        "    super(Generator, self).__init__(name = name, **kwargs)\n",
        "    self.reshape = tf.keras.layers.Reshape((8,8,1))\n",
        "    self.convtrans1 = tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size = (3,3), \n",
        "                                                      activation = tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
        "    self.convtrans2 = tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (3,3),\n",
        "                                               activation = tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
        "    self.upsampling = tf.keras.layers.UpSampling2D(size = (2,2))\n",
        "    self.convtrans3 =tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size = (3,3),\n",
        "                                                     activation = tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
        "    self.convtrans4 = tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (3,3),\n",
        "                                                       activation = tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
        "    self.convtrans5 = tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (3,3),\n",
        "                                                      activation = tf.keras.layers.LeakyReLU(alpha = 0.2))\n",
        "    self.out3 = tf.keras.layers.Conv2DTranspose(filters = 3, kernel_size = (3,3), activation = 'sigmoid')\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x = self.reshape(inputs)\n",
        "    x = self.convtrans1(x)\n",
        "    x = self.convtrans2(x)\n",
        "    x = self.upsampling(x)\n",
        "    x = self.convtrans3(x)\n",
        "    x = self.convtrans4(x)\n",
        "    x = self.convtrans5(x)\n",
        "    return self.out3(x)\n",
        "    "
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k-zVxZgDji1"
      },
      "source": [
        "mygen = Generator(name = 'generator')\n",
        "inputs = tf.keras.Input(shape = (64,))\n",
        "outputs = mygen(inputs)\n",
        "gen_mod = tf.keras.Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYK94E5GEQRA",
        "outputId": "a1ebd577-34e0-479f-e842-1a206fcad686"
      },
      "source": [
        "gen_mod.summary()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "generator (Generator)        (None, 32, 32, 3)         373187    \n",
            "=================================================================\n",
            "Total params: 373,187\n",
            "Trainable params: 373,187\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8r49hs44aYt"
      },
      "source": [
        "discriminator = tf.keras.models.Sequential([\n",
        "                            tf.keras.Input(shape = (28,28,1)),\n",
        "                            tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "                            tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
        "                            tf.keras.layers.GlobalMaxPooling2D(),\n",
        "                            tf.keras.layers.Dense(units = 1)\n",
        "], name = 'discriminator')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PH0xOp94ajX"
      },
      "source": [
        "latent_dim = 128\n",
        "generator = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(latent_dim,)),\n",
        "        tf.keras.layers.Dense(7 * 7 * 128),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Reshape((7, 7, 128)),\n",
        "        tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
        "        tf.keras.layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXVa-hohEt1a"
      },
      "source": [
        "#The GAN using model subclassing (We merge the above classes in one)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3vMzRZPQpe_"
      },
      "source": [
        "class GAN(tf.keras.Model):\n",
        "  def __init__(self, discriminator, generator, latent_dim):\n",
        "    super(GAN, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "  \n",
        "  def compile(self, d_optm, g_optm, d_loss):\n",
        "    super(GAN, self).compile()\n",
        "    self.d_optm = d_optm\n",
        "    self.g_optm = g_optm\n",
        "    self.d_loss = d_loss\n",
        "  \n",
        "  def train_step(self, real_imgs):\n",
        "    if isinstance(real_imgs, tuple):\n",
        "      real_imgs = real_imgs[0]\n",
        "    batch_size = tf.shape(real_imgs)[0]\n",
        "    #Sample some points in the latent space\n",
        "    rand_latent_vecs = tf.random.normal(shape = (batch_size, self.latent_dim))\n",
        "    #Fake images generation\n",
        "    fake_img = self.generator(rand_latent_vecs)\n",
        "    #Concat with real data(images)\n",
        "    imgs_combined = tf.concat([fake_img, real_imgs], axis = 0)\n",
        "    labels = tf.concat([\n",
        "                        tf.ones(shape = (batch_size, 1)), tf.zeros(shape = (batch_size,1))\n",
        "    ], axis = 0)\n",
        "    labels+=0.05 * tf.random.uniform(tf.shape(labels))\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(imgs_combined)\n",
        "      loss = self.d_loss(labels, predictions)\n",
        "    grads = tape.gradient(loss, self.discriminator.trainable_weights)\n",
        "    self.d_optm.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "    rand_latent_vecs = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "    misleading_labels = tf.zeros((batch_size, 1))\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self.discriminator(self.generator(rand_latent_vecs))\n",
        "      g_loss = self.d_loss(misleading_labels, predictions)\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optm.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "    return {\"d_loss\": loss, \"g_loss\": g_loss}\n",
        "      "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQn3zME-XGKV",
        "outputId": "8fc4d192-350c-4879-95c8-5c0c1227ec80"
      },
      "source": [
        "# Prepare the dataset. We use both the training & test MNIST digits.\n",
        "batch_size = 64\n",
        "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
        "all_images = np.concatenate([x_train, x_test])\n",
        "all_images = all_images.astype(\"float32\") / 255.0\n",
        "all_images = np.reshape(all_images, (-1, 28, 28, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(all_images)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "gan = GAN(latent_dim= latent_dim, generator = generator, discriminator = discriminator)\n",
        "gan.compile(\n",
        "    d_optm=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optm=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    d_loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "# To limit the execution time, we only train on 100 batches. You can train on\n",
        "# the entire dataset. You will need about 20 epochs to get nice results.\n",
        "gan.fit(dataset.take(100), epochs=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 342s 3s/step - d_loss: 0.4850 - g_loss: 0.8030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b42f059b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asscT0Yzas4g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}